<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Advanced usage • bayesplay</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Advanced usage">
<meta property="og:description" content="bayesplay">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">bayesplay</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.9.4</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/advanced.html">Advanced usage</a>
    </li>
    <li>
      <a href="../articles/basic.html">Basic usage</a>
    </li>
    <li>
      <a href="../articles/default_ttests.html">Default t-tests</a>
    </li>
    <li>
      <a href="../articles/plots.html">Basic plotting</a>
    </li>
    <li>
      <a href="../articles/robustness.html">Robustness regions</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/bayesplay/bayesplay/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Advanced usage</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/bayesplay/bayesplay/blob/HEAD/vignettes/advanced.Rmd" class="external-link"><code>vignettes/advanced.Rmd</code></a></small>
      <div class="hidden name"><code>advanced.Rmd</code></div>

    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/bayesplay/bayesplay" class="external-link">bayesplay</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org" class="external-link">ggplot2</a></span><span class="op">)</span></span></code></pre></div>
<p>This vignette demonstrates some of the advanced features of the
<code>bayesplay</code> package.</p>
<p>The advanced features include:</p>
<ul>
<li><p><a href="#calculating-posterior-distributions">Calculating and
plotting posterior distributions</a></p></li>
<li><p><a href="#the-savage-dickey-density-ratio">Computing Bayes
factors using the Savage-Dickey density ratio</a></p></li>
<li><p><a href="#marginal-predictions">Extracting and plotting marginal
predictions</a></p></li>
<li><p><a href="#visually-comparing-models">Visually comparing marginal
predictions for different priors</a></p></li>
</ul>
<div class="section level2">
<h2 id="calculating-posterior-distributions">Calculating posterior distributions<a class="anchor" aria-label="anchor" href="#calculating-posterior-distributions"></a>
</h2>
<p>Bayes theorem defines a posterior distribution according to the
follows:</p>
<p><span class="math display">\[P(\theta|X) =
\frac{P(X|\theta)\cdot{}P(\theta)}{P(X)},\]</span></p>
<p>where <span class="math inline">\(P(X|\theta)\)</span> is the
likelihood (the conditional probability of the data given the parameter
value) and <span class="math inline">\(P(\theta)\)</span> and <span class="math inline">\(P(X)\)</span> are the (unconditional)
<em>prior</em> probability of the parameter and marginal likelihood,
respectively.</p>
<p>Often in presentations of Bayes theorem, the marginal likelihood,
<span class="math inline">\(P(X)\)</span>, is omitted and Bayes theorem
is given as follows:</p>
<p><span class="math display">\[P(\theta|X) \propto
P(X|\theta)\cdot{}P(\theta).\]</span></p>
<p>One reason for this may be that the concept of the marginal
likelihood is a tricky concept to grasp. However, the <em>law of total
probability</em> give the marginal likelihood as follows:</p>
<p><span class="math display">\[P(X)=
\int{}P(X|\theta)\cdot{}P(\theta)d\theta,\]</span></p>
<p>where <span class="math inline">\(P(X|\theta)\)</span>, and <span class="math inline">\(P(X)\)</span> are again the likelihood and the
prior, respectively. This should be familiar from the computation of the
Bayes factor. Simply put, the marginal likelihood is the <em>weighted
average</em> of the likelihood function where the prior provides the
weights.</p>
<p>Given this, all that is needed to compute a posterior is a prior and
a likelihood. Let us walk through a few examples using a few different
likelihoods and priors.</p>
<div class="section level3">
<h3 id="binomial-likelihood-and-beta-prior">Binomial likelihood and beta prior<a class="anchor" aria-label="anchor" href="#binomial-likelihood-and-beta-prior"></a>
</h3>
<p>First, we’ll use a <em>binomial</em> likelihood with a <em>beta</em>
prior. First, we’ll define the likelihood and the prior, and then we’ll
multiply the two together, as given by the <em>proportional</em> form of
Bayes theorem.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># first the likelihood</span></span>
<span><span class="va">l</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/likelihood.html">likelihood</a></span><span class="op">(</span>family <span class="op">=</span> <span class="st">"binomial"</span>, successes <span class="op">=</span> <span class="fl">2</span>, trials <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">l</span></span>
<span><span class="co">#&gt; Likelihood</span></span>
<span><span class="co">#&gt;   Family</span></span>
<span><span class="co">#&gt;     binomial</span></span>
<span><span class="co">#&gt;   Parameters</span></span>
<span><span class="co">#&gt;     successes: 2</span></span>
<span><span class="co">#&gt;     trials: 10</span></span>
<span><span class="co">#&gt; </span></span></code></pre></div>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># then the prior</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/prior.html">prior</a></span><span class="op">(</span>family <span class="op">=</span> <span class="st">"beta"</span>, alpha <span class="op">=</span> <span class="fl">2.5</span>, beta <span class="op">=</span> <span class="fl">3.5</span><span class="op">)</span></span>
<span><span class="va">p</span></span>
<span><span class="co">#&gt; Prior</span></span>
<span><span class="co">#&gt;   Family</span></span>
<span><span class="co">#&gt;     beta</span></span>
<span><span class="co">#&gt;   Parameters</span></span>
<span><span class="co">#&gt;     alpha: 2.5</span></span>
<span><span class="co">#&gt;     beta: 3.5</span></span>
<span><span class="co">#&gt; </span></span></code></pre></div>
<p>Once both the prior and the likelihood have been defined then we can
simply multiply the two together.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">prod</span> <span class="op">&lt;-</span> <span class="va">l</span> <span class="op">*</span> <span class="va">p</span></span>
<span><span class="va">prod</span></span>
<span><span class="co">#&gt; Product</span></span>
<span><span class="co">#&gt;   Likelihood family: binomial</span></span>
<span><span class="co">#&gt;   Prior family: beta</span></span>
<span><span class="co">#&gt;   Area under curve: 0.1294</span></span></code></pre></div>
<p>Let us draw a few plots of the objects that we’ve just created.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot.html">plot</a></span><span class="op">(</span><span class="va">l</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"binomial likelihood"</span>, subtitle <span class="op">=</span> <span class="st">"2 successes out of 10 trials"</span><span class="op">)</span></span></code></pre></div>
<p><img src="advanced_files/figure-html/unnamed-chunk-5-1.png" width="700"></p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot.html">plot</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"beta prior"</span>, subtitle <span class="op">=</span> <span class="st">"alpha = 2.5, beta = 3.5"</span><span class="op">)</span></span></code></pre></div>
<p><img src="advanced_files/figure-html/unnamed-chunk-6-1.png" width="700"></p>
<p>Finally, we can plot the product of these two plots. That is, the we
simply multiply together the two <span class="math inline">\(y\)</span>
values (from the plots above) for each value of <span class="math inline">\(x\)</span>. This give the following:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot.html">plot</a></span><span class="op">(</span><span class="va">prod</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"product of the likelihood and prior"</span>, subtitle <span class="op">=</span> <span class="st">"for a binomial likelihood and beta prior"</span><span class="op">)</span></span></code></pre></div>
<p><img src="advanced_files/figure-html/unnamed-chunk-7-1.png" width="700"></p>
<p>The product of the prior and the likelihood is <em>proportional</em>
to the posterior distribution, but it is <em>not</em> the posterior
distribution. In fact, it is not a <em>proper probability
distribution</em>, because the area under the curve is not equal to 1.
However, we could <em>normalise</em> it, by dividing the above plot by
normalising constant equal to the area under the curve. That is, we
could normalise it by dividing it by the <em>marginal
likelihood</em>.</p>
<p>We can compute the marginal likelihood by simply computing the
integral of the product, as follows:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/integral.html">integral</a></span><span class="op">(</span><span class="va">prod</span><span class="op">)</span></span>
<span><span class="co">#&gt; 0.1293755</span></span></code></pre></div>
<p>And we can perform this normalisation in the <code>bayesplay</code>
package by using the <code><a href="../reference/extract_posterior.html">extract_posterior()</a></code> function.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">posterior1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/extract_posterior.html">extract_posterior</a></span><span class="op">(</span><span class="va">prod</span><span class="op">)</span></span>
<span><span class="va">posterior1</span></span>
<span><span class="co">#&gt; Posterior</span></span>
<span><span class="co">#&gt; Likelihood</span></span>
<span><span class="co">#&gt;   binomial</span></span>
<span><span class="co">#&gt;     successes: 2</span></span>
<span><span class="co">#&gt;     trials: 10</span></span>
<span><span class="co">#&gt; Prior</span></span>
<span><span class="co">#&gt;   beta</span></span>
<span><span class="co">#&gt;     alpha: 2.5</span></span>
<span><span class="co">#&gt;     beta: 3.5</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Normalising constant: 0.1294</span></span></code></pre></div>
<p>Now we can plot the posterior distribution:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot.html">plot</a></span><span class="op">(</span><span class="va">posterior1</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"posterior distribution"</span>, subtitle <span class="op">=</span> <span class="st">"for a binomial likelihood and beta prior"</span><span class="op">)</span></span></code></pre></div>
<p><img src="advanced_files/figure-html/unnamed-chunk-10-1.png" width="700"></p>
</div>
<div class="section level3">
<h3 id="normal-likelihood-and-uniform-prior">Normal likelihood and uniform prior<a class="anchor" aria-label="anchor" href="#normal-likelihood-and-uniform-prior"></a>
</h3>
<p>We can now repeat the process using a different likelihood and prior.
We can compute the posterior and plot it in just two steps.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">posterior2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/extract_posterior.html">extract_posterior</a></span><span class="op">(</span><span class="fu"><a href="../reference/likelihood.html">likelihood</a></span><span class="op">(</span><span class="st">"normal"</span>, <span class="fl">10</span>, <span class="fl">14</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="../reference/prior.html">prior</a></span><span class="op">(</span><span class="st">"uniform"</span>, <span class="op">-</span><span class="fl">30</span>, <span class="fl">30</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/plot.html">plot</a></span><span class="op">(</span><span class="va">posterior2</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"posterior distribution"</span>, subtitle <span class="op">=</span> <span class="st">"normal likelihood and uniform prior"</span><span class="op">)</span></span></code></pre></div>
<p><img src="advanced_files/figure-html/unnamed-chunk-11-1.png" width="700"></p>
</div>
<div class="section level3">
<h3 id="noncentral-d-likelihood-and-cauchy-prior">Noncentral ‘d’ likelihood and Cauchy prior<a class="anchor" aria-label="anchor" href="#noncentral-d-likelihood-and-cauchy-prior"></a>
</h3>
<p>And finally, we can repeat the process using a noncentral ‘d’
(noncentral <em>t</em> distribution scaled in terms of effect size) and
a Cauchy prior.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">posterior3</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/extract_posterior.html">extract_posterior</a></span><span class="op">(</span><span class="fu"><a href="../reference/likelihood.html">likelihood</a></span><span class="op">(</span><span class="st">"noncentral_d"</span>, <span class="fl">.8</span>, <span class="fl">25</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="../reference/prior.html">prior</a></span><span class="op">(</span><span class="st">"cauchy"</span>, <span class="fl">0</span>, <span class="fl">.707</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/plot.html">plot</a></span><span class="op">(</span><span class="va">posterior3</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"posterior distribution"</span>, subtitle <span class="op">=</span> <span class="st">"noncentral 'd' likelihood and cauchy prior"</span><span class="op">)</span></span></code></pre></div>
<p><img src="advanced_files/figure-html/unnamed-chunk-12-1.png" width="700"></p>
</div>
</div>
<div class="section level2">
<h2 id="plotting-priors-and-posteriors">Plotting priors and posteriors<a class="anchor" aria-label="anchor" href="#plotting-priors-and-posteriors"></a>
</h2>
<p>The prior and posterior can be thought of representing
<em>beliefs</em> about the parameter values <em>before</em> and
<em>after</em> seeing the data. For this reason, it can often be
desirable to plot priors and posteriors together to observe how beliefs
have been <em>reallocated</em> or <em>updated</em> as a result of
observing the data.</p>
<p>When plotting a posterior, the <code><a href="../reference/plot.html">plot()</a></code> function can take
a second argument to indicate that the prior should be included in the
plot.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot.html">plot</a></span><span class="op">(</span><span class="va">posterior1</span>, add_prior <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"prior and posterior distribution"</span>, subtitle <span class="op">=</span> <span class="st">"for a binomial likelihood and beta prior"</span><span class="op">)</span></span></code></pre></div>
<p><img src="advanced_files/figure-html/unnamed-chunk-13-1.png" width="700"></p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot.html">plot</a></span><span class="op">(</span><span class="va">posterior2</span>, add_prior <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"prior and posterior distribution"</span>, subtitle <span class="op">=</span> <span class="st">"normal likelihood and uniform prior"</span><span class="op">)</span></span></code></pre></div>
<p><img src="advanced_files/figure-html/unnamed-chunk-14-1.png" width="700"></p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot.html">plot</a></span><span class="op">(</span><span class="va">posterior3</span>, add_prior <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"prior posterior distribution"</span>, subtitle <span class="op">=</span> <span class="st">"noncentral 'd' likelihood and cauchy prior"</span><span class="op">)</span></span></code></pre></div>
<p><img src="advanced_files/figure-html/unnamed-chunk-15-1.png" width="700"></p>
</div>
<div class="section level2">
<h2 id="the-savage-dickey-density-ratio">The Savage-Dickey density ratio<a class="anchor" aria-label="anchor" href="#the-savage-dickey-density-ratio"></a>
</h2>
<p>Once we have a posterior distribution at hand then it is possible to
calculate a Bayes factor using the Savage-Dickey density ratio. This
Bayes factor is equal to the Bayes factor that is calculated by
comparing the full model to a restricted model that is nested in the
full model. For example, consider the following Bayes factor:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/likelihood.html">likelihood</a></span><span class="op">(</span><span class="st">"binomial"</span>, successes <span class="op">=</span> <span class="fl">2</span>, trials <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">prior_alt</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/prior.html">prior</a></span><span class="op">(</span><span class="st">"beta"</span>, <span class="fl">2.5</span>, <span class="fl">3.5</span><span class="op">)</span></span>
<span><span class="va">prior_null</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/prior.html">prior</a></span><span class="op">(</span><span class="st">"point"</span>, <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="va">bf</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/integral.html">integral</a></span><span class="op">(</span><span class="va">data_model</span> <span class="op">*</span> <span class="va">prior_alt</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="../reference/integral.html">integral</a></span><span class="op">(</span><span class="va">data_model</span> <span class="op">*</span> <span class="va">prior_null</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">bf</span><span class="op">)</span></span>
<span><span class="co">#&gt; Bayes factor</span></span>
<span><span class="co">#&gt;  Using the levels from Wagenmakers et al (2017)</span></span>
<span><span class="co">#&gt;  A BF of 2.944 indicates:</span></span>
<span><span class="co">#&gt;  Anecdotal evidence</span></span></code></pre></div>
<p>This Bayes factor uses the same likelihood that we used to compute
<code>posterior1</code>, and the alternative prior is the same prior we
used to compute <code>posterior1</code>. The null prior in this case is
a <em>nested</em> inside the alternative prior. That is, it is a
restriction of the alternative prior.</p>
<p>As an alternative, we could compute this Bayes factor using the
Savage-Dickey density ratio by comparing the density of the prior at
<span class="math inline">\(\theta\)</span> = 0.5 to the density of the
posterior at same value. We can do this with the <code>bayesplay</code>
package by using the <code><a href="../reference/sd_ratio.html">sd_ratio()</a></code> function and specifying
<code>point = 0.5</code>.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bf1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sd_ratio.html">sd_ratio</a></span><span class="op">(</span><span class="va">posterior1</span>, point <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">bf1</span><span class="op">)</span></span>
<span><span class="co">#&gt; Bayes factor</span></span>
<span><span class="co">#&gt;  Using the levels from Wagenmakers et al (2017)</span></span>
<span><span class="co">#&gt;  A BF of 2.944 indicates:</span></span>
<span><span class="co">#&gt;  Anecdotal evidence</span></span></code></pre></div>
<p>As can be seen, the two Bayes factors are identical.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/identical.html" class="external-link">identical</a></span><span class="op">(</span><span class="va">bf</span>, <span class="va">bf1</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] FALSE</span></span></code></pre></div>
<p>We can repeat this for the other posterior distributions.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bf2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sd_ratio.html">sd_ratio</a></span><span class="op">(</span><span class="va">posterior2</span>, point <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">bf2</span><span class="op">)</span></span>
<span><span class="co">#&gt; Bayes factor</span></span>
<span><span class="co">#&gt;  Using the levels from Wagenmakers et al (2017)</span></span>
<span><span class="co">#&gt;  A BF of 0.6954 indicates:</span></span>
<span><span class="co">#&gt;  Anecdotal evidence</span></span></code></pre></div>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bf3</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sd_ratio.html">sd_ratio</a></span><span class="op">(</span><span class="va">posterior3</span>, point <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">bf3</span><span class="op">)</span></span>
<span><span class="co">#&gt; Bayes factor</span></span>
<span><span class="co">#&gt;  Using the levels from Wagenmakers et al (2017)</span></span>
<span><span class="co">#&gt;  A BF of 61.0607 indicates:</span></span>
<span><span class="co">#&gt;  Very strong evidence</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="marginal-predictions">Marginal predictions<a class="anchor" aria-label="anchor" href="#marginal-predictions"></a>
</h2>
<p>We can think of priors are <em>models of our hypotheses</em>. That
is, they represent our <em>pre-data</em> beliefs about the parameter
values, or what our hypotheses <em>predict</em> about the parameter
values. When we run experiments, however, we don’t collect data on the
parameter values directly. Instead, we collect observations.</p>
<p>Consider the following example: We are conducting a coin-flipping and
we’re collecting observations in terms of the <em>number of heads</em>
in our <em>series of 10 flips</em>. We might have two hypotheses, one
where we hypothesize that the coin bias is exactly 0.2 and another where
we hypothesize that the coin bias is exactly 0.8. We might this that
these two hypotheses predict that we should obtain 2/10 heads and 8/10
heads, respectively. However, these two outcomes are only the most
likely observations under the two hypotheses. That is, other outcomes
are possible, although they’d be less likely that these two particular
outcomes. But what exactly is the distribution of <em>expected data</em>
for each of these two hypotheses?</p>
<p>To work this out, we’ll first need to define a likelihood. Because
this is coin flipping experiment we’ll use a <em>binomial</em>
likelihood, and since our experiment is going to consist of 10 flips,
we’ll set the <code>trials</code> parameter to 10. For the
<code>successes</code> parameter, we simply set it to an arbitrary
value—for example, 5. This value will be highlighted in the subsequent
plots, so it can also be useful to examining observations relative to
some <em>reference</em> observation.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/likelihood.html">likelihood</a></span><span class="op">(</span><span class="st">"binomial"</span>, successes <span class="op">=</span> <span class="fl">5</span>, trials <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<p>We then specify two priors that represent our two hypotheses.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">hypothesis1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/prior.html">prior</a></span><span class="op">(</span><span class="st">"point"</span>, <span class="fl">.2</span><span class="op">)</span></span>
<span><span class="va">hypothesis2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/prior.html">prior</a></span><span class="op">(</span><span class="st">"point"</span>, <span class="fl">.8</span><span class="op">)</span></span></code></pre></div>
<p>By plotting the two priors we can see that each prior assigns all the
probability weight to a single bias value.</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># prior for model 1</span></span>
<span><span class="fu"><a href="../reference/plot.html">plot</a></span><span class="op">(</span><span class="va">hypothesis1</span><span class="op">)</span></span></code></pre></div>
<p><img src="advanced_files/figure-html/unnamed-chunk-23-1.png" width="700"></p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># prior for model 2</span></span>
<span><span class="fu"><a href="../reference/plot.html">plot</a></span><span class="op">(</span><span class="va">hypothesis2</span><span class="op">)</span></span></code></pre></div>
<p><img src="advanced_files/figure-html/unnamed-chunk-24-1.png" width="700"></p>
<p>We, however, what to know the <em>observations</em> that each model
predictions. To work this out, we first multiply our data model (that
is, our likelihood were the observation has been left out) by each of
the priors.</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model1</span> <span class="op">&lt;-</span> <span class="va">data_model</span> <span class="op">*</span> <span class="va">hypothesis1</span></span>
<span><span class="va">model2</span> <span class="op">&lt;-</span> <span class="va">data_model</span> <span class="op">*</span> <span class="va">hypothesis2</span></span></code></pre></div>
<p>We then use the <code><a href="../reference/extract_predictions.html">extract_predictions()</a></code> function to
extract the marginal predictions for the resulting product of the
likelihood and the prior. We can then plot these predictions using the
<code><a href="../reference/plot.html">plot()</a></code> function.</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># predictions of model 1</span></span>
<span><span class="va">model1_predictions</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/extract_predictions.html">extract_predictions</a></span><span class="op">(</span><span class="va">model1</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/plot.html">plot</a></span><span class="op">(</span><span class="va">model1_predictions</span><span class="op">)</span></span></code></pre></div>
<p><img src="advanced_files/figure-html/unnamed-chunk-26-1.png" width="700"></p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># predictions of model 2</span></span>
<span><span class="va">model2_predictions</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/extract_predictions.html">extract_predictions</a></span><span class="op">(</span><span class="va">model2</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/plot.html">plot</a></span><span class="op">(</span><span class="va">model2_predictions</span><span class="op">)</span></span></code></pre></div>
<p><img src="advanced_files/figure-html/unnamed-chunk-27-1.png" width="700"></p>
<p>What we see in each of these plots is marginal probability of
<em>each observation</em> for our given data model and prior. That is,
we see the <em>predictions</em> in terms of <em>observations</em> for
each model.</p>
</div>
<div class="section level2">
<h2 id="visually-comparing-models">Visually comparing models<a class="anchor" aria-label="anchor" href="#visually-comparing-models"></a>
</h2>
<p>Although looking at each set of model predictions can be useful to
see what sort of observations we should expect viewing each model on
it’s on is of limited value. Instead, what we can do is compare the two
model are see how the predicted observations for each model differs.</p>
<p>To this, we can use the <code><a href="../reference/visual_compare.html">visual_compare()</a></code> function.</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/visual_compare.html">visual_compare</a></span><span class="op">(</span><span class="va">model1</span>, <span class="va">model2</span><span class="op">)</span></span></code></pre></div>
<p><img src="advanced_files/figure-html/unnamed-chunk-28-1.png" width="700"></p>
<p>Since these plots show the <em>marginal probability</em> of different
observation over prior, the values in the plots are related to the Bayes
factor. In fact, the ratio of the two plots <em>at a particular
observation</em> is the Bayes factor for that observation. The
<code><a href="../reference/visual_compare.html">visual_compare()</a></code> function contains an extra parameter,
<code>ratio</code>, which can be set to <code>TRUE</code> to directly
display the ratio. The resulting plot show the Log10 Bayes factor for
each observation. The ratio plot also shows a horizontal line for the
equivalence point. Intersections between the ratio plot and equivalence
line correspond to observations at which neither model is favoured—that
is, the marginal likelihoods are the same and the ratio of the marginal
likelihoods is 1.</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/visual_compare.html">visual_compare</a></span><span class="op">(</span><span class="va">model1</span>, <span class="va">model2</span>, ratio <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p><img src="advanced_files/figure-html/unnamed-chunk-29-1.png" width="700"></p>
<p>We’re not restricted to examining <em>binomial</em> likelihoods. We
can examine any of the likelihoods and priors available in the
<code>bayesplay</code> package. For example, we can examine the
predictions for a <em>noncentral ‘d’</em> likelihood and <em>cauchy</em>
and <em>point</em> priors. To do this, we set the value of our
observation, <code>d</code> to an arbitrary value—for example, 0, and
set <code>n</code> to the planned sample size our our experiment.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data_model2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/likelihood.html">likelihood</a></span><span class="op">(</span><span class="st">"noncentral_d"</span>, d <span class="op">=</span> <span class="fl">0</span>, n <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></span></code></pre></div>
<p>Now we can specify a <em>point</em> prior, and a <em>Cauchy</em>
prior and multiply them by the likelihood.</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">d_model1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/extract_predictions.html">extract_predictions</a></span><span class="op">(</span><span class="va">data_model2</span> <span class="op">*</span> <span class="fu"><a href="../reference/prior.html">prior</a></span><span class="op">(</span><span class="st">"cauchy"</span>, <span class="fl">0</span>, <span class="fl">.707</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">d_model2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/extract_predictions.html">extract_predictions</a></span><span class="op">(</span><span class="va">data_model2</span> <span class="op">*</span> <span class="fu"><a href="../reference/prior.html">prior</a></span><span class="op">(</span><span class="st">"point"</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot.html">plot</a></span><span class="op">(</span><span class="va">d_model1</span><span class="op">)</span></span></code></pre></div>
<p><img src="advanced_files/figure-html/unnamed-chunk-32-1.png" width="700"></p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot.html">plot</a></span><span class="op">(</span><span class="va">d_model2</span><span class="op">)</span></span></code></pre></div>
<p><img src="advanced_files/figure-html/unnamed-chunk-33-1.png" width="700"></p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/visual_compare.html">visual_compare</a></span><span class="op">(</span><span class="va">d_model1</span>, <span class="va">d_model2</span><span class="op">)</span></span></code></pre></div>
<p><img src="advanced_files/figure-html/unnamed-chunk-34-1.png" width="700"></p>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/visual_compare.html">visual_compare</a></span><span class="op">(</span><span class="va">d_model1</span>, <span class="va">d_model2</span>, ratio <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p><img src="advanced_files/figure-html/unnamed-chunk-35-1.png" width="700"></p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Lincoln John Colling.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
